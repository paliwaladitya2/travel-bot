# -*- coding: utf-8 -*-
"""IntentClassification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1kOv9vFco-EHGZiDX5ECJyNOt4X8lrTSx
"""

import pandas as pd
import numpy as np
import nltk

df = pd.read_csv('/content/f3.csv')

from google.colab import drive
drive.mount('/content/drive')

df.head()

sentences = df['X']

from nltk.corpus import stopwords
nltk.download('stopwords')
nltk.download('wordnet')
nltk.download('punkt')

STOPWORDS = set(stopwords.words('english'))
def remove_stopwords(text):
    """custom function to remove the stopwords"""
    return " ".join([word for word in str(text).split() if word not in STOPWORDS])

sentences = sentences.apply(lambda text: remove_stopwords(text.lower()))
sentences.head()

from nltk.stem import WordNetLemmatizer

lemmatizer = WordNetLemmatizer()
def lemmatize_words(text):
    return " ".join([lemmatizer.lemmatize(word) for word in text.split()])

sentences = sentences.apply(lambda text: lemmatize_words(text))
sentences.head()

bow = {}
i = 1
for row in sentences:
  for word in row.split(" "):
    if word not in bow:
      bow[word] = i
      i += 1

X = []
for i in sentences:
  X.append(nltk.word_tokenize(i))

X

bow

bow = {'10k': 56,
 '4/5': 70,
 '5000': 16,
 '5k': 48,
 'activity': 20,
 'actually': 88,
 'adventure': 71,
 'adventurous': 19,
 'around': 47,
 'available': 63,
 'away': 78,
 'back': 105,
 'best': 58,
 'book': 1,
 'booking': 5,
 'budget': 15,
 'camping': 87,
 'city': 79,
 'class': 65,
 'complete': 101,
 'day': 30,
 'delhi': 54,
 'done': 35,
 'economy': 64,
 'family': 22,
 'find': 61,
 'finding': 51,
 'flight': 44,
 'friend': 59,
 'friendly': 102,
 'full': 110,
 'get': 62,
 'go': 21,
 'going': 104,
 'good': 11,
 'heard': 90,
 'help': 4,
 'hey': 42,
 'hi': 80,
 'hill': 75,
 'historic': 27,
 'historical': 57,
 'hoping': 60,
 'hotel': 2,
 'imagica': 45,
 'iternary': 13,
 'k': 24,
 'kolkata': 55,
 'lake': 86,
 'like': 36,
 'look': 43,
 'looking': 39,
 'low': 46,
 'moderate': 66,
 'monument': 100,
 'nearby': 77,
 'need': 49,
 'one': 29,
 'overnight': 85,
 'park': 92,
 'parking': 83,
 'per': 17,
 'person': 18,
 'place': 28,
 'plan': 12,
 'planning': 72,
 'please': 38,
 'prefer': 106,
 'pune': 14,
 'pune,': 93,
 'rate': 67,
 'really': 52,
 'recommend': 53,
 'recomment': 10,
 'relaxing': 94,
 'relieve': 99,
 'rupee': 25,
 'scenic': 96,
 'searching': 7,
 'seeing': 74,
 'shanirwada': 37,
 'show': 9,
 'sight': 73,
 'sorry': 109,
 'spend': 23,
 'star': 69,
 'station': 76,
 'stay': 40,
 'suggest': 98,
 'thanks': 108,
 'theme': 91,
 'think': 8,
 'thinking': 95,
 'today': 41,
 'tour': 82,
 'travelling': 107,
 'trek': 103,
 'trekking': 84,
 'trip': 31,
 'two': 68,
 'vested': 89,
 'view': 97,
 'visit': 26,
 'visited': 34,
 'visiting': 111,
 'wa': 6,
 'want': 3,
 'wanted': 81,
 'weekend': 33,
 'whole': 32,
 'would': 50}

import pickle

with open('bow.pickle', 'wb') as file:
  pickle.dump(bow, file, protocol=pickle.HIGHEST_PROTOCOL)

classes = {
    "Hotel":0,
    "Flights":1,
    "Iterarnary":2
}

# Mapping the classes
df['Class'] = df['Y'].map(classes)

labels = df['Class']

labels

sentences

trainData = []
for i in X:
  temp = []
  for word in i:
    if word in bow:
      a = bow.get(word)
      temp.append(a)
  trainData.append(temp)

trainData

import tensorflow as tf

padded_data = tf.keras.preprocessing.sequence.pad_sequences(trainData, maxlen=16, padding='post')

padded_data

from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler(feature_range=(1,110))
scaled_data = scaler.fit_transform(padded_data)

scaled_data

from sklearn.model_selection import train_test_split

Xtr, Xte, Ytr, Yte = train_test_split(scaled_data, labels, test_size = 0.2)

Xtr.shape

Xtr

Ytr.shape

from tensorflow.keras import Sequential
from tensorflow.keras.layers import LSTM, Dense, Bidirectional, Flatten, Embedding, Dropout, Input, SimpleRNN
from tensorflow.keras.optimizers import Adam, SGD

model = Sequential([
              #  LSTM(128, input_shape=(1,5,10), activation="tanh"),
              LSTM(128, activation="tanh", return_sequences=True),
              LSTM(64, activation="tanh", return_sequences=True),
              LSTM(32, activation="tanh"),
              Dropout(0.2),
              Flatten(),
              Dense(64,activation="relu"),
              Dropout(0.2),
              Dense(32, activation="relu"),
              Dense(3, activation="softmax")
])

model.compile(loss="sparse_categorical_crossentropy", optimizer=Adam(lr=0.01), metrics=['accuracy'])

Xtr = np.expand_dims(Xtr, axis=-1)

hist = model.fit(Xtr, Ytr, epochs=50)

model.evaluate(Xte, Yte)

model.save('app.h5')

Xtr[2].shape

Xtr[2]

text = "Recommend me a place to stay"

def preprocess(text):
  st = str.lower(text)
  st = remove_stopwords(st)
  st = lemmatize_words(st)
  return st

preprocess_text = preprocess(text)

preprocess_text = nltk.word_tokenize(preprocess_text)

sample = []
for i in preprocess_text:
  if i in bow:
    a = bow.get(i)
    print(a)
    sample.append(a)
  else:
    sample.append(0)

sample = np.array(sample)

sample

output = model.predict(np.expand_dims(sample, axis=0))

# output = model.predict(np.expand_dims(Xtr[2], axis=0))

output

listofclasses = ["Hotel", "Flights", "Iterarnary"]
c = np.argmax(output)
print(listofclasses[c])

!pip install -q -U "tensorflow-text==2.8.*"

!pip install -q tf-models-official==2.7.0

from official.nlp import optimization  # to create AdamW optimizer

!pip install -U tensorflow-text==2.5

import tensorflow_hub as hub
import tensorflow_text as text

import tensorflow as tf

tfhub_handle_encoder = 'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1'

tfhub_handle_preprocess = 'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3'

bert_model = hub.KerasLayer(tfhub_handle_encoder)

def build_classifier_model():
  text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')
  preprocessing_layer = hub.KerasLayer(tfhub_handle_preprocess, name='preprocessing')
  encoder_inputs = preprocessing_layer(text_input)
  encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=True, name='BERT_encoder')
  outputs = encoder(encoder_inputs)
  net = outputs['pooled_output']
  net = tf.keras.layers.Dense(16, activation="relu")(net)
  net = tf.keras.layers.Dropout(0.1)(net)
  net = tf.keras.layers.Dense(3, activation="softmax", name='classifier')(net)
  return tf.keras.Model(text_input, net)

classifier_model = build_classifier_model()

loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)
metrics = tf.metrics.SparseCategoricalAccuracy()

epochs = 5
steps_per_epoch = 5
num_train_steps = steps_per_epoch * epochs
num_warmup_steps = int(0.1*num_train_steps)

init_lr = 3e-5
optimizer = optimization.create_optimizer(init_lr=init_lr,
                                          num_train_steps=num_train_steps,
                                          num_warmup_steps=num_warmup_steps,
                                          optimizer_type='adamw')

classifier_model.compile(optimizer=optimizer,
                         loss=loss,
                         metrics=metrics)

from sklearn.model_selection import train_test_split

btr, bte, bltr, blte = train_test_split(sentences, labels, test_size = 0.2)

btr.shape

btr = np.array(btr).reshape(80,1)

bltr.shape

history = classifier_model.fit(x=btr, y=bltr, epochs=10)

loss, accuracy = classifier_model.evaluate(bte, blte)

print(f'Loss: {loss}')
print(f'Accuracy: {accuracy}')

output = classifier_model.predict(["Adventures in Pune"])

output

listofclasses = ["Hotel", "Flights", "Iterarnary"]
c = np.argmax(output)
print(listofclasses[c])

classifier_model.save('bert_model.h5')